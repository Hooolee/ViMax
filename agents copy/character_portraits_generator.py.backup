import logging
import os
import asyncio
import tempfile
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain.chat_models.base import BaseChatModel
from langchain.chat_models import init_chat_model
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
from tenacity import retry, stop_after_attempt
from interfaces import CharacterInScene, CharacterAppearance, ImageOutput
from langchain_core.messages import HumanMessage, SystemMessage
from utils.retry import after_func



prompt_template_front = \
"""
Generate a full-body, front-view portrait of character {identifier} based on the following description, with a pure white background. The character should be centered in the image, occupying most of the frame. Gazing straight ahead. Standing with arms relaxed at sides. {emotional_expression}
Features: {features}
Style: {style}
"""

prompt_template_side = \
"""
Generate a full-body, side-view portrait of character {identifier} based on the provided front-view portrait, with a pure white background. The character should be centered in the image, occupying most of the frame. Facing left. Standing with arms relaxed at sides. {emotional_expression}
"""

prompt_template_back = \
"""
Generate a full-body, back-view portrait of character {identifier} based on the provided front-view portrait, with a pure white background. The character should be centered in the image, occupying most of the frame. No facial features should be visible.
"""


# æƒ…ç»ªçŠ¶æ€åˆ°è¡¨æƒ…çš„æ˜ å°„
EMOTIONAL_EXPRESSIONS = {
    "neutral": "Natural, neutral expression.",
    "tired": "Tired, weary expression with slight fatigue visible.",
    "energetic": "Energetic, lively expression with bright eyes.",
    "sad": "Sad, melancholic expression.",
    "angry": "Angry, intense expression.",
    "happy": "Happy, cheerful expression with a smile.",
    "excited": "Excited, enthusiastic expression.",
    "depressed": "Depressed, downcast expression.",
    "anxious": "Anxious, worried expression.",
    "confident": "Confident, self-assured expression.",
    "relaxed": "Relaxed, calm expression.",
}


class CharacterPortraitsGenerator:
    def __init__(
        self,
        image_generator,
    ):
        self.image_generator = image_generator


    @retry(stop=stop_after_attempt(3), after=after_func, reraise=True)
    async def generate_front_portrait(
        self,
        character: CharacterInScene,
        style: str,
        appearance: Optional[CharacterAppearance] = None,
    ) -> ImageOutput:
        """ç”Ÿæˆè§’è‰²çš„æ­£é¢è‚–åƒ
        
        Args:
            character: è§’è‰²ä¿¡æ¯
            style: é£æ ¼æè¿°
            appearance: ç‰¹å®šå¤–è§‚ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¤–è§‚æˆ–ä»dynamic_featuresåˆ›å»ºï¼‰
        
        Returns:
            ImageOutput: ç”Ÿæˆçš„å›¾åƒè¾“å‡º
        """
        logging.info("="*80)
        logging.info(f"ğŸ¨ [Agent: CharacterPortraitsGenerator] Generating front portrait for {character.identifier_in_scene}...")
        
        # ç¡®å®šä½¿ç”¨å“ªä¸ªå¤–è§‚
        if appearance is None:
            appearance = character.appearances[0] if character.appearances else None
        
        if appearance:
            logging.info(f"   Using appearance: {appearance.appearance_id} - {appearance.description}")
            logging.info("="*80)
            features = "(static) " + character.static_features + "; (dynamic) " + appearance.dynamic_features
            emotional_expression = EMOTIONAL_EXPRESSIONS.get(
                appearance.emotional_state or "neutral", 
                "Natural expression."
            )
        else:
            # å‘åå…¼å®¹ï¼šä½¿ç”¨æ—§çš„ dynamic_features
            logging.info(f"   Using legacy dynamic_features (backward compatibility)")
            logging.info("="*80)
            features = "(static) " + character.static_features + "; (dynamic) " + character.dynamic_features
            emotional_expression = "Natural expression."
        
        prompt = prompt_template_front.format(
            identifier=character.identifier_in_scene,
            features=features,
            style=style,
            emotional_expression=emotional_expression,
        )
        image_output = await self.image_generator.generate_single_image(
            prompt=prompt,
            # size="512x512",
        )
        return image_output

    @retry(stop=stop_after_attempt(3), after=after_func, reraise=True)
    async def generate_side_portrait(
        self,
        character: CharacterInScene,
        front_image_path: str,
        appearance: Optional[CharacterAppearance] = None,
    ) -> ImageOutput:
        """ç”Ÿæˆè§’è‰²çš„ä¾§é¢è‚–åƒ
        
        Args:
            character: è§’è‰²ä¿¡æ¯
            front_image_path: æ­£é¢è‚–åƒçš„è·¯å¾„
            appearance: ç‰¹å®šå¤–è§‚ï¼ˆç”¨äºè·å–æƒ…ç»ªè¡¨æƒ…ï¼‰
        
        Returns:
            ImageOutput: ç”Ÿæˆçš„å›¾åƒè¾“å‡º
        """
        # ç¡®å®šæƒ…ç»ªè¡¨æƒ…
        if appearance is None:
            appearance = character.appearances[0] if character.appearances else None
        
        emotional_expression = "Natural expression."
        if appearance and appearance.emotional_state:
            emotional_expression = EMOTIONAL_EXPRESSIONS.get(
                appearance.emotional_state,
                "Natural expression."
            )
        
        prompt = prompt_template_side.format(
            identifier=character.identifier_in_scene,
            emotional_expression=emotional_expression,
        )
        image_output = await self.image_generator.generate_single_image(
            prompt=prompt,
            reference_image_paths=[front_image_path],
            # size="1024x1024",
        )
        return image_output


    @retry(stop=stop_after_attempt(3), after=after_func, reraise=True)
    async def generate_back_portrait(
        self,
        character: CharacterInScene,
        front_image_path: str,
    ) -> ImageOutput:
        """ç”Ÿæˆè§’è‰²çš„èƒŒé¢è‚–åƒ
        
        Args:
            character: è§’è‰²ä¿¡æ¯
            front_image_path: æ­£é¢è‚–åƒçš„è·¯å¾„
        
        Returns:
            ImageOutput: ç”Ÿæˆçš„å›¾åƒè¾“å‡º
        """
        prompt = prompt_template_back.format(
            identifier=character.identifier_in_scene,
        )
        image_output = await self.image_generator.generate_single_image(
            prompt=prompt,
            reference_image_paths=[front_image_path],
            # size="512x512",
        )
        return image_output
    
    
    async def generate_portraits_for_appearance(
        self,
        character: CharacterInScene,
        appearance: CharacterAppearance,
        style: str,
    ) -> Dict[str, ImageOutput]:
        """ä¸ºè§’è‰²çš„ç‰¹å®šå¤–è§‚ç”Ÿæˆä¸‰è§†å›¾è‚–åƒ
        
        Args:
            character: è§’è‰²ä¿¡æ¯
            appearance: ç‰¹å®šå¤–è§‚
            style: é£æ ¼æè¿°
        
        Returns:
            Dict[str, ImageOutput]: åŒ…å« 'front', 'side', 'back' ä¸‰ä¸ªè§†å›¾çš„å­—å…¸
        """
        logging.info("="*80)
        logging.info(f"ğŸ¨ [Agent: CharacterPortraitsGenerator] Generating portraits for {character.identifier_in_scene}")
        logging.info(f"   Appearance: {appearance.appearance_id} - {appearance.description}")
        logging.info(f"   Scenes: {appearance.scene_ids if appearance.scene_ids else 'all'}")
        logging.info(f"   Emotional state: {appearance.emotional_state}")
        logging.info("="*80)
        
        # ç”Ÿæˆæ­£é¢è‚–åƒ
        front_output = await self.generate_front_portrait(character, style, appearance)
        
        # å°†æ­£é¢è‚–åƒä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œä¾›ä¾§é¢å’ŒèƒŒé¢ç”Ÿæˆä½¿ç”¨
        with tempfile.NamedTemporaryFile(mode='wb', suffix='.png', delete=False) as tmp_file:
            front_temp_path = tmp_file.name
            front_output.save(front_temp_path)
        
        try:
            # ç”Ÿæˆä¾§é¢å’ŒèƒŒé¢è‚–åƒ
            side_output = await self.generate_side_portrait(character, front_temp_path, appearance)
            back_output = await self.generate_back_portrait(character, front_temp_path)
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(front_temp_path):
                os.unlink(front_temp_path)
        
        return {
            "front": front_output,
            "side": side_output,
            "back": back_output,
        }
    
    
    async def generate_all_appearances_for_character(
        self,
        character: CharacterInScene,
        style: str,
    ) -> Dict[str, Dict[str, ImageOutput]]:
        """ä¸ºè§’è‰²çš„æ‰€æœ‰å¤–è§‚ç”Ÿæˆè‚–åƒ
        
        Args:
            character: è§’è‰²ä¿¡æ¯
            style: é£æ ¼æè¿°
        
        Returns:
            Dict[str, Dict[str, ImageOutput]]: 
                å¤–å±‚keyæ˜¯appearance_idï¼Œå†…å±‚æ˜¯ {'front', 'side', 'back'}
                ä¾‹å¦‚: {
                    'appearance_0': {'front': ImageOutput, 'side': ImageOutput, 'back': ImageOutput},
                    'appearance_1': {'front': ImageOutput, 'side': ImageOutput, 'back': ImageOutput},
                }
        """
        logging.info("="*80)
        logging.info(f"ğŸ­ [Agent: CharacterPortraitsGenerator] Generating ALL appearances for {character.identifier_in_scene}")
        logging.info(f"   Total appearances: {len(character.appearances)}")
        logging.info("="*80)
        
        results = {}
        for appearance in character.appearances:
            portraits = await self.generate_portraits_for_appearance(
                character, appearance, style
            )
            results[appearance.appearance_id] = portraits
            
            logging.info(f"âœ… Completed {appearance.appearance_id} for {character.identifier_in_scene}")
        
        logging.info("="*80)
        logging.info(f"ğŸ‰ All appearances generated for {character.identifier_in_scene}")
        logging.info("="*80)
        
        return results
